# This is the basic transformer training setting with speaker embedding.
# This configuration reuqires 1 gpus in the case of each gpu memory = 12GB, and it takes 2~3 days.

# network architecture related
model-module: espnet.nets.pytorch_backend.e2e_ltt_transformer:Transformer
# embed-dim: 0
cdim: 512
eprenet-conv-layers: 3  # one more linear layer w/o non-linear will be added for 0-centor
eprenet-conv-filts: 3
eprenet-conv-chans: 128
adim: 384
aheads: 4
elayers: 3
eunits: 1536
dlayers: 3
dunits: 1536
use-weighted-masking: True
use-batch-norm: True
use-scaled-pos-enc: True
encoder-normalize-before: False
decoder-normalize-before: False
encoder-concat-after: False
decoder-concat-after: False
reduction-factor: 1
use-speaker-embedding: false
spk-embed-integration-type: add
use-image-input: false
image-height: 64
image-width: 128

transformer-input-layer: linear # conv2d-scaled-pos-enc

# minibatch related
batch-sort-key: input # shuffle or input or output
batch-bins: 250000
# batch-bins: 2500000   
                      # batch-size * (max_out * dim_out + max_in * dim_in)
                      # 5203 batches containing from 5 to 354 samples (avg 28 samples).

# training related
transformer-init: pytorch
transformer-warmup-steps: 4000
transformer-lr: 1.0
initial-encoder-alpha: 1.0
initial-decoder-alpha: 1.0
eprenet-dropout-rate: 0.0
transformer-enc-dropout-rate: 0.5
transformer-enc-positional-dropout-rate: 0.5
transformer-enc-attn-dropout-rate: 0.5
transformer-dec-dropout-rate: 0.1
transformer-dec-positional-dropout-rate: 0.1
transformer-dec-attn-dropout-rate: 0.1
transformer-enc-dec-attn-dropout-rate: 0.1

# optimization related
opt: noam
accum-grad: 1
grad-clip: 1.0
weight-decay: 0.0
patience: 0
epochs: 100 # 100 * 5,203 / 4 = 130,075 iters

# other
num-save-attention: 0
save-interval-epochs: 5
eval-interval-epochs: 5
